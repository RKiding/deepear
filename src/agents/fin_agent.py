import os
import time
from datetime import datetime
from typing import List, Optional
from agno.agent import Agent
from agno.models.base import Model
from loguru import logger

from utils.database_manager import DatabaseManager
from tools.toolkits import StockToolkit, SearchToolkit, NewsToolkit
from prompts.fin_agent import (
    get_fin_researcher_instructions, 
    get_fin_analyst_instructions,
    get_fin_research_task,
    format_research_context,
    get_fin_analysis_task,
    get_tracking_analysis_task
)
from schema.models import InvestmentSignal, ResearchContext
from utils.json_utils import extract_json

class FinAgent:
    """
    é‡‘èåˆ†æå¸ˆ (FinAgent) - è´Ÿè´£æ·±åº¦åˆ†æé‡‘èä¿¡å·å¹¶å…³è”å…·ä½“çš„æŠ•èµ„æ ‡çš„
    é‡‡ç”¨åŒæ¨¡å‹æ¶æ„ï¼šTool Model è´Ÿè´£ä¿¡æ¯æ£€ç´¢ï¼ŒReasoning Model è´Ÿè´£æ·±åº¦åˆ†æä¸ç»“æ„åŒ–è¾“å‡ºã€‚
    """
    
    def __init__(self, db: DatabaseManager, model: Model, tool_model: Optional[Model] = None, isq_template_id: str = "default_isq_v1"):
        self.db = db
        self.model = model  # Reasoning Model
        self.tool_model = tool_model or model  # Tool Model
        self.isq_template_id = isq_template_id
        
        # åˆå§‹åŒ–å·¥å…·åŒ…
        self.stock_toolkit = StockToolkit(db)
        self.search_toolkit = SearchToolkit(db)
        self.news_toolkit = NewsToolkit(db)
        
        # 1. ç ”ç©¶å‘˜ Agent (è´Ÿè´£ä½¿ç”¨å·¥å…·æœé›†ä¿¡æ¯)
        self.researcher = Agent(
            model=self.tool_model,
            tools=[
                self.stock_toolkit.search_ticker,
                self.stock_toolkit.get_stock_price,
                self.search_toolkit.web_search,
                self.news_toolkit.fetch_news_content,
            ],
            instructions=[get_fin_researcher_instructions()],
            markdown=False,
            debug_mode=True,
            output_schema=ResearchContext if hasattr(self.tool_model, 'response_format') else None
        )

        # 2. åˆ†æå¸ˆ Agent (è´Ÿè´£æ·±åº¦é€»è¾‘æ¨ç†å’Œ JSON è¾“å‡º)
        self.analyst = Agent(
            model=self.model,
            instructions=[get_fin_analyst_instructions(template_id=self.isq_template_id)],
            markdown=False,
            debug_mode=True,
            output_schema=InvestmentSignal if hasattr(self.model, 'response_format') else None
        )
        
        logger.info(f"ğŸ’¼ FinAgent initialized (Dual-Model: Reasoning={self.model.id}, Tool={self.tool_model.id}, ISQ={self.isq_template_id})")

    def analyze_signal(self, signal_text: str, news_id: str = None, max_retries: int = 3) -> Optional[InvestmentSignal]:
        """
        åˆ†æå…·ä½“çš„é‡‘èä¿¡å·å¹¶è¿”å›ç»“æ„åŒ–çš„ InvestmentSignal
        é‡‡ç”¨åŒæ¨¡å‹æ¶æ„ï¼šTool Model æœé›†æ•°æ® -> Reasoning Model æ·±åº¦åˆ†æ
        """
        
        logger.info(f"ğŸ’¼ FinAgent starting dual-phase analysis for: {signal_text[:50]}...")
        
        # ç¬¬ä¸€é˜¶æ®µï¼šç ”ç©¶å‘˜æœé›†ä¿¡æ¯ï¼ˆä½¿ç”¨ Tool Modelï¼‰
        research_task = get_fin_research_task(signal_text)
        research_context_str = ""
        research_raw_response = ""
        research_data = None
        
        try:
            logger.info("ğŸ“Š Phase 1: Researcher gathering information using tools...")
            research_response = self.researcher.run(research_task)
            research_raw_response = research_response.content if hasattr(research_response, 'content') else str(research_response)
            
            # ç›´æ¥ä½¿ç”¨ç ”ç©¶å‘˜çš„å®Œæ•´è¾“å‡ºï¼ˆåŒ…å«å·¥å…·è°ƒç”¨ç»“æœï¼‰
            research_context_str = research_raw_response
            
            # åŒæ—¶å°è¯•è§£æç»“æ„åŒ–æ•°æ®ç”¨äºæ—¥å¿—è®°å½•
            research_data = extract_json(research_raw_response)
            if research_data:
                logger.info(f"âœ… Research phase completed. Found tickers: {research_data.get('tickers_found', [])}")
            else:
                logger.info("âœ… Research phase completed (unstructured format)")
                
        except Exception as e:
            logger.warning(f"âš ï¸ Research phase failed: {e}. Proceeding with raw signal only.")
            research_context_str = "ï¼ˆç ”ç©¶é˜¶æ®µå¤±è´¥ï¼Œå°†ä»…åŸºäºåŸå§‹ä¿¡å·è¿›è¡Œåˆ†æï¼‰"

        # ç¬¬äºŒé˜¶æ®µï¼šåˆ†æå¸ˆåŸºäºå®Œæ•´èƒŒæ™¯è¿›è¡Œæ·±åº¦åˆ†æï¼ˆä½¿ç”¨ Reasoning Modelï¼‰
        # åŒ…å«è¯¦ç»†çš„å·¥å…·è°ƒç”¨ç»“æœå’ŒåŸå§‹ä¿¡å·
        analysis_task = get_fin_analysis_task(signal_text, research_context_str)
        
        logger.info("ğŸ§  Phase 2: Analyst performing deep ISQ analysis...")
        
        for attempt in range(max_retries):
            try:
                response = self.analyst.run(analysis_task)
                content = response.content if hasattr(response, 'content') else str(response)
                
                # è°ƒè¯•æ—¥å¿—ï¼šæ˜¾ç¤ºåˆ†æå¸ˆçš„è¾“å‡ºé•¿åº¦
                logger.debug(f"Analyst response length: {len(content)} chars")
                
                # å°è¯•ä»å†…å®¹ä¸­æå– JSON
                json_data = extract_json(content)
                if json_data:
                    # è¡¥å…¨ news_id å¦‚æœæœ‰
                    if news_id and not json_data.get('signal_id'):
                        json_data['signal_id'] = news_id

                    # Sanitize tickers to avoid low-quality hallucinated associations.
                    json_data = self._sanitize_signal_output(json_data, research_data=research_data, raw_signal=signal_text)
                    
                    logger.info(f"âœ… Analysis completed successfully (attempt {attempt + 1}/{max_retries})")
                    logger.debug(f"Extracted signal: {json_data.get('title', 'N/A')}, confidence: {json_data.get('confidence', 'N/A')}")
                    
                    # è½¬æ¢ä¸ºæ¨¡å‹å¯¹è±¡
                    return InvestmentSignal(**json_data)
                
                raise ValueError("Could not extract valid JSON from response")
                
            except Exception as e:
                logger.warning(f"âš ï¸ FinAgent analysis attempt {attempt + 1}/{max_retries} failed: {e}")
                if attempt < max_retries - 1:
                    logger.info(f"Retrying in {2 ** attempt} seconds...")
                    time.sleep(2 ** attempt)
                else:
                    logger.error("âŒ FinAgent analysis failed after all retries")
                    return None

    @staticmethod
    def _clean_digits(value: str) -> str:
        s = (value or "").strip()
        if not s:
            return ""
        return "".join([c for c in s if c.isdigit()])

    def _sanitize_signal_output(self, json_data: dict, research_data: Optional[dict] = None, raw_signal: str = "") -> dict:
        """Post-process LLM output to prevent spurious ticker/name binding.

        Rules (conservative by default):
        - impact_tickers must be valid A/H numeric codes present in cached stock_list.
        - The ticker must be supported by evidence: it appears in signal title/summary/source titles/urls,
          OR it was returned via the researcher's structured tickers_found.
        - The displayed name is overwritten by the official name from stock_list.
        """
        if not isinstance(json_data, dict):
            return json_data

        tool_suggested: set[str] = set()
        if isinstance(research_data, dict):
            tf = research_data.get('tickers_found')
            if isinstance(tf, list):
                for item in tf:
                    if not isinstance(item, dict):
                        continue
                    code_raw = item.get('code') or item.get('ticker') or item.get('symbol')
                    code = self._clean_digits(str(code_raw or ""))
                    if code:
                        tool_suggested.add(code)

        sources = json_data.get('sources')
        source_titles: list[str] = []
        source_urls: list[str] = []
        if isinstance(sources, list):
            for s in sources:
                if not isinstance(s, dict):
                    continue
                t = str(s.get('title') or "").strip()
                u = str(s.get('url') or "").strip()
                if t:
                    source_titles.append(t)
                if u:
                    source_urls.append(u)

        evidence_text = " ".join([
            str(raw_signal or ""),
            str(json_data.get('title') or ""),
            str(json_data.get('summary') or ""),
            " ".join(source_titles),
            " ".join(source_urls),
        ])

        impact = json_data.get('impact_tickers')
        if not isinstance(impact, list) or not impact:
            return json_data

        sanitized: list[dict] = []
        for item in impact:
            if not isinstance(item, dict):
                continue
            code_raw = item.get('ticker') or item.get('code') or item.get('symbol')
            code = self._clean_digits(str(code_raw or ""))
            if not (code.isdigit() and len(code) in (5, 6)):
                continue

            stock = self.db.get_stock_by_code(code)
            if not stock:
                continue
            official_name = stock.get('name') or ""

            # Evidence gate: allow if suggested by tools OR explicitly mentioned in evidence.
            mentioned = (code in evidence_text) or (official_name and official_name in evidence_text)
            if tool_suggested:
                if code not in tool_suggested and not mentioned:
                    continue
            else:
                if not mentioned:
                    continue

            new_item = dict(item)
            new_item['ticker'] = code
            new_item['name'] = official_name
            sanitized.append(new_item)

        json_data['impact_tickers'] = sanitized
        return json_data

    def track_signal(self, old_signal: dict, max_retries: int = 3) -> Optional[InvestmentSignal]:
        """
        è¿½è¸ªå¹¶æ›´æ–°å·²æœ‰ä¿¡å·çš„çŠ¶æ€ï¼ˆUpdate/Tracking Modeï¼‰
        1. ç ”ç©¶å‘˜ï¼šé’ˆå¯¹è¯¥ä¿¡å·æœé›†æœ€æ–°è¿›å±•ï¼ˆPrice + Newsï¼‰
        2. åˆ†æå¸ˆï¼šå¯¹æ¯”æ–°æ—§ä¿¡æ¯ï¼Œè¾“å‡º Evolution
        """
        title = old_signal.get("title", "Unknown")
        logger.info(f"ğŸ”„ Tracking signal evolution: {title}")
        
        # 1. é’ˆå¯¹æ€§æœé›†æœ€æ–°ä¿¡æ¯
        # æ„é€ ä¸€ä¸ªä¾§é‡äºâ€œè¿‘æœŸå˜åŒ–â€çš„ç ”ç©¶ä»»åŠ¡
        research_task = f"è¯·è¿½è¸ªã€{title}ã€‘çš„æœ€æ–°è¿›å±•ã€‚é‡ç‚¹æŸ¥è¯¢ï¼š1. æœ€è¿‘çš„è‚¡ä»·èµ°åŠ¿å’Œå…³é”®å…¬å‘Šã€‚2. åŸæœ‰çš„é€»è¾‘ï¼ˆ{old_signal.get('summary', '')}ï¼‰æ˜¯å¦å‘ç”Ÿå˜åŒ–ï¼ŸåŒ…å«å…·ä½“çš„æ–°é—»æ ‡é¢˜å’Œä»·æ ¼ã€‚"
        
        research_context_str = ""
        research_data = None
        
        try:
            logger.info(f"ğŸ“Š Tracking Phase 1: Researching updates for {title}...")
            research_response = self.researcher.run(research_task)
            research_raw_response = research_response.content if hasattr(research_response, 'content') else str(research_response)
            research_context_str = research_raw_response
            research_data = extract_json(research_raw_response)
        except Exception as e:
            logger.warning(f"âš ï¸ Tracking research failed: {e}")
            research_context_str = "ï¼ˆè¿½è¸ªç ”ç©¶å¤±è´¥ï¼Œä»…åŸºäºå·²æœ‰æ•°æ®ï¼‰"
            
        # 2. åˆ†æå¸ˆæ‰§è¡Œè¿½è¸ªæ›´æ–°
        tracking_task = get_tracking_analysis_task(old_signal, research_context_str)
        
        logger.info(f"ğŸ§  Tracking Phase 2: Analyst evaluating evolution...")
        
        for attempt in range(max_retries):
            try:
                response = self.analyst.run(tracking_task)
                content = response.content if hasattr(response, 'content') else str(response)
                
                json_data = extract_json(content)
                if json_data:
                    # ä¿æŒ ID ä¸å˜
                    json_data['signal_id'] = old_signal.get('signal_id', f"evolved_{int(time.time())}")
                    
                    # Sanitize
                    json_data = self._sanitize_signal_output(json_data, research_data=research_data, raw_signal=f"Tracking: {title}")
                    
                    logger.info(f"âœ… Tracking completed for {title}")
                    return InvestmentSignal(**json_data)
                    
                raise ValueError("No valid JSON in tracking response")
                
            except Exception as e:
                logger.warning(f"âš ï¸ Tracking attempt {attempt + 1} failed: {e}")
                if attempt < max_retries - 1:
                    time.sleep(2)
                    
        return None

    def run(self, task: str) -> str:
        """é€šç”¨è¿è¡Œå…¥å£ - ä½¿ç”¨åˆ†æå¸ˆ Agent æ‰§è¡Œä»»åŠ¡"""
        response = self.analyst.run(task)
        return response.content if hasattr(response, 'content') else str(response)

