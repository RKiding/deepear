import os
from typing import Dict, List, Union, Optional
import json
from loguru import logger
from agno.agent import Agent
from utils.llm.factory import get_model
from utils.database_manager import DatabaseManager

# ä»ç¯å¢ƒå˜é‡è¯»å–é»˜è®¤æƒ…ç»ªåˆ†ææ¨¡å¼
DEFAULT_SENTIMENT_MODE = os.getenv("SENTIMENT_MODE", "auto")  # auto, bert, llm

class SentimentTools:
    """
    æƒ…ç»ªåˆ†æå·¥å…· - æ”¯æŒ LLM å’Œ BERT ä¸¤ç§æ¨¡å¼
    
    æ¨¡å¼è¯´æ˜:
    - "auto": è‡ªåŠ¨é€‰æ‹©ï¼Œä¼˜å…ˆä½¿ç”¨ BERTï¼ˆé€Ÿåº¦å¿«ï¼‰ï¼Œä¸å¯ç”¨æ—¶å›é€€åˆ° LLM
    - "bert": å¼ºåˆ¶ä½¿ç”¨ BERT æ¨¡å‹ï¼ˆéœ€è¦ transformers åº“ï¼‰
    - "llm": å¼ºåˆ¶ä½¿ç”¨ LLMï¼ˆæ›´å‡†ç¡®ä½†è¾ƒæ…¢ï¼‰
    
    å¯é€šè¿‡ç¯å¢ƒå˜é‡ SENTIMENT_MODE è®¾ç½®é»˜è®¤æ¨¡å¼ã€‚
    """
    
    def __init__(self, db: DatabaseManager, mode: Optional[str] = None, 
                 model_provider: str = "openai", model_id: str = "gpt-4o"):
        """
        åˆå§‹åŒ–æƒ…ç»ªåˆ†æå·¥å…·ã€‚
        
        Args:
            db: æ•°æ®åº“ç®¡ç†å™¨å®ä¾‹
            mode: åˆ†ææ¨¡å¼ï¼Œå¯é€‰ "auto", "bert", "llm"ã€‚None åˆ™ä½¿ç”¨ç¯å¢ƒå˜é‡é»˜è®¤å€¼ã€‚
            model_provider: LLM æä¾›å•†ï¼Œå¦‚ "openai", "ust", "deepseek"
            model_id: æ¨¡å‹æ ‡è¯†ç¬¦
        """
        self.db = db
        self.mode = mode or DEFAULT_SENTIMENT_MODE
        self.llm_model = None
        self.bert_pipeline = None
        
        # Initialize LLM
        try:
            provider = "ust" if os.getenv("UST_KEY_API") else model_provider
            m_id = "Qwen" if provider == "ust" else model_id
            self.llm_model = get_model(provider, m_id)
        except Exception as e:
            logger.warning(f"LLM initialization skipped: {e}")

        # Initialize BERT if needed
        if self.mode in ["bert", "auto"]:
            try:
                from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
                from transformers.utils import logging as transformers_logging
                transformers_logging.set_verbosity_error() # å‡å°‘å†—ä½™æ—¥å¿—
                
                bert_model = os.getenv("BERT_SENTIMENT_MODEL", "uer/roberta-base-finetuned-chinanews-chinese")
                
                # ä¼˜å…ˆä½¿ç”¨æœ¬åœ°ç¼“å­˜
                try:
                    tokenizer = AutoTokenizer.from_pretrained(bert_model, local_files_only=True)
                    model = AutoModelForSequenceClassification.from_pretrained(bert_model, local_files_only=True)
                    
                    self.bert_pipeline = pipeline(
                        "sentiment-analysis", 
                        model=model,
                        tokenizer=tokenizer,
                        device=-1
                    )
                    logger.info(f"âœ… BERT pipeline loaded from local cache: {bert_model}")
                except (OSError, ValueError, ImportError):
                    # æœ¬åœ°æ²¡æœ‰ï¼Œåˆ™ä»ç½‘ç»œä¸‹è½½
                    logger.info(f"ğŸ“¡ Downloading BERT model: {bert_model}...")
                    tokenizer = AutoTokenizer.from_pretrained(bert_model)
                    model = AutoModelForSequenceClassification.from_pretrained(bert_model)
                    
                    self.bert_pipeline = pipeline(
                        "sentiment-analysis", 
                        model=model,
                        tokenizer=tokenizer,
                        device=-1
                    )
                    logger.info(f"âœ… BERT Sentiment pipeline ({bert_model}) initialized.")
            except ImportError:
                logger.warning("Transformers library not installed. BERT sentiment analysis disabled.")
            except Exception as e:
                if self.mode == "bert":
                    logger.error(f"BERT mode requested but failed: {e}")
                else:
                    logger.warning(f"BERT unavailable, using LLM only. Error: {e}")
                self.bert_pipeline = None


    def analyze_sentiment(self, text: str) -> Dict[str, Union[float, str]]:
        """
        åˆ†ææ–‡æœ¬çš„æƒ…ç»ªææ€§ã€‚æ ¹æ®åˆå§‹åŒ–æ—¶çš„ mode è‡ªåŠ¨é€‰æ‹©åˆ†ææ–¹æ³•ã€‚
        
        Args:
            text: éœ€è¦åˆ†æçš„æ–‡æœ¬å†…å®¹ï¼Œå¦‚æ–°é—»æ ‡é¢˜æˆ–æ‘˜è¦ã€‚
        
        Returns:
            åŒ…å«ä»¥ä¸‹å­—æ®µçš„å­—å…¸:
            - score: æƒ…ç»ªåˆ†å€¼ï¼ŒèŒƒå›´ -1.0ï¼ˆæåº¦è´Ÿé¢ï¼‰åˆ° 1.0ï¼ˆæåº¦æ­£é¢ï¼‰ï¼Œ0.0 ä¸ºä¸­æ€§
            - label: æƒ…ç»ªæ ‡ç­¾ï¼Œ"positive"/"negative"/"neutral"
            - reason: åˆ†æç†ç”±ï¼ˆä»… LLM æ¨¡å¼æä¾›è¯¦ç»†ç†ç”±ï¼‰
        """
        if self.mode == "bert" and self.bert_pipeline:
            results = self.analyze_sentiment_bert([text])
            return results[0] if results else {"score": 0.0, "label": "error"}
        elif self.mode == "llm" or (self.mode == "auto" and not self.bert_pipeline):
            return self.analyze_sentiment_llm(text)
        else:
            # auto mode with BERT available
            results = self.analyze_sentiment_bert([text])
            return results[0] if results else {"score": 0.0, "label": "error"}

    def analyze_sentiment_llm(self, text: str) -> Dict[str, Union[float, str]]:
        """
        ä½¿ç”¨ LLM è¿›è¡Œæ·±åº¦æƒ…ç»ªåˆ†æï¼Œå¯è·å¾—è¯¦ç»†çš„åˆ†æç†ç”±ã€‚
        
        Args:
            text: éœ€è¦åˆ†æçš„æ–‡æœ¬ï¼Œæœ€å¤šå¤„ç†å‰ 1000 å­—ç¬¦ã€‚
        
        Returns:
            åŒ…å« score, label, reason çš„å­—å…¸ã€‚
        """
        if not self.llm_model:
            return {"score": 0.0, "label": "neutral", "error": "LLM not initialized"}

        analyzer = Agent(model=self.llm_model, markdown=False)
        prompt = f"""è¯·åˆ†æä»¥ä¸‹é‡‘è/æ–°é—»æ–‡æœ¬çš„æƒ…ç»ªææ€§ã€‚
        è¿”å›ä¸¥æ ¼çš„ JSON æ ¼å¼:   
        {{"score": <float: -1.0åˆ°1.0>, "label": "<positive/negative/neutral>", "reason": "<ç®€çŸ­ç†ç”±>"}}

        æ–‡æœ¬: {text[:1000]}"""

        try:
            response = analyzer.run(prompt)
            content = response.content
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                content = content.split("```")[1].split("```")[0].strip()
            return json.loads(content)
        except Exception as e:
            logger.error(f"LLM sentiment failed: {e}")
            return {"score": 0.0, "label": "error", "reason": str(e)}

    def analyze_sentiment_bert(self, texts: List[str]) -> List[Dict]:
        """
        ä½¿ç”¨ BERT è¿›è¡Œæ‰¹é‡é«˜é€Ÿæƒ…ç»ªåˆ†æã€‚
        
        Args:
            texts: éœ€è¦åˆ†æçš„æ–‡æœ¬åˆ—è¡¨ã€‚
        
        Returns:
            ä¸è¾“å…¥åˆ—è¡¨ç­‰é•¿çš„åˆ†æç»“æœåˆ—è¡¨ã€‚
        """
        if not self.bert_pipeline:
            return [{"score": 0.0, "label": "error", "reason": "BERT not available"}] * len(texts)
        
        try:
            results = self.bert_pipeline(texts, truncation=True, max_length=512)
            processed = []
            for r in results:
                label = r['label'].lower()
                score = r['score']
                
                # æ ‡å‡†åŒ–ä¸åŒæ¨¡å‹çš„æ ‡ç­¾æ ¼å¼
                if 'negative' in label or 'neg' in label:
                    score = -score
                elif 'neutral' in label or 'neu' in label:
                    score = 0.0
                
                processed.append({
                    "score": float(round(score, 3)),
                    "label": "positive" if score > 0.1 else ("negative" if score < -0.1 else "neutral"),
                    "reason": "BERT automated analysis"
                })
            return processed
        except Exception as e:
            logger.error(f"BERT analysis failed: {e}")
            return [{"score": 0.0, "label": "error", "reason": str(e)}] * len(texts)

    def batch_update_news_sentiment(self, source: Optional[str] = None, limit: int = 50, use_bert: Optional[bool] = None):
        """
        æ‰¹é‡æ›´æ–°æ•°æ®åº“ä¸­æ–°é—»çš„æƒ…ç»ªåˆ†æ•°ã€‚
        
        Args:
            source: ç­›é€‰ç‰¹å®šæ–°é—»æºï¼Œå¦‚ "wallstreetcn"ã€‚None åˆ™å¤„ç†æ‰€æœ‰æ¥æºã€‚
            limit: æœ€å¤šå¤„ç†çš„æ–°é—»æ•°é‡ã€‚
            use_bert: æ˜¯å¦ä½¿ç”¨ BERTã€‚None åˆ™æ ¹æ®åˆå§‹åŒ–æ¨¡å¼è‡ªåŠ¨å†³å®šã€‚
        
        Returns:
            æˆåŠŸæ›´æ–°çš„æ–°é—»æ•°é‡ã€‚
        """
        news_items = self.db.get_daily_news(source=source, limit=limit)
        to_analyze = [item for item in news_items if not item.get('sentiment_score')]
        
        if not to_analyze:
            return 0

        # å†³å®šä½¿ç”¨å“ªç§æ–¹æ³•
        should_use_bert = use_bert if use_bert is not None else (self.bert_pipeline is not None and self.mode != "llm")

        updated_count = 0
        cursor = self.db.conn.cursor()
        
        if should_use_bert and self.bert_pipeline:
            logger.info(f"ğŸš€ Using BERT for batch analysis of {len(to_analyze)} items...")
            titles = [item['title'] for item in to_analyze]
            results = self.analyze_sentiment_bert(titles)
            
            for item, analysis in zip(to_analyze, results):
                cursor.execute("""
                    UPDATE daily_news 
                    SET sentiment_score = ?, meta_data = json_set(COALESCE(meta_data, '{}'), '$.sentiment_reason', ?)
                    WHERE id = ?
                """, (analysis['score'], analysis['reason'], item['id']))
                updated_count += 1
        else:
            logger.info(f"ğŸš¶ Using LLM for analysis of {len(to_analyze)} items...")
            for item in to_analyze:
                analysis = self.analyze_sentiment_llm(item['title'])
                cursor.execute("""
                    UPDATE daily_news 
                    SET sentiment_score = ?, meta_data = json_set(COALESCE(meta_data, '{}'), '$.sentiment_reason', ?)
                    WHERE id = ?
                """, (analysis.get('score', 0.0), analysis.get('reason', ''), item['id']))
                updated_count += 1
        
        self.db.conn.commit()
        return updated_count
