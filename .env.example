# LLM Configuration (Dual-Model Routing)
# Reasoning Model: Used for deep analysis, writing, and logic.
REASONING_MODEL_PROVIDER='openrouter' # options: openai, ollama, deepseek, dashscope, openrouter
REASONING_MODEL_ID='gpt-4o'
REASONING_MODEL_HOST=''        # Optional: specific host for reasoning model (e.g. for Ollama)

# Tool Model: Used for tool calling, searching, and data fetching.
TOOL_MODEL_PROVIDER='ollama'
TOOL_MODEL_ID='qwen3:latest'
TOOL_MODEL_HOST='http://127.0.0.1:11434' # Optional: specific host for tool model

# Legacy/Default Configuration (Fallback)
LLM_PROVIDER='openrouter' 
LLM_MODEL='gpt-4o'    
LLM_HOST=''

# Provider API Keys
OPENAI_API_KEY=''
DEEPSEEK_API_KEY=''
DASHSCOPE_API_KEY=''
OPENROUTER_API_KEY=''

# UST Provider Configuration (HKUST-GZ AI)
UST_KEY_API=''
UST_URL=''

# Sentiment Analysis Settings
SENTIMENT_MODE='auto' # options: auto (priority BERT), bert, llm
BERT_SENTIMENT_MODEL='uer/roberta-base-finetuned-chinanews-chinese'

# Search and Extraction Settings
EMBEDDING_MODEL='paraphrase-multilingual-MiniLM-L12-v2'
SEARCH_CACHE_TTL='3600'  # Cache time for search results (seconds)
JINA_READER_KEY=''       # Optional: for higher rate of web content crawling (r.jina.ai)